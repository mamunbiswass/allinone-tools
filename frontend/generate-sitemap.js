import fs from "fs";
import path from "path";

// ‚úÖ Domain name (‡¶∂‡ßá‡¶∑‡ßá "/" ‡¶•‡¶æ‡¶ï‡¶¨‡ßá ‡¶®‡¶æ)
const BASE_URL = "https://quicktoolspro.in";

// üìÅ React page folder path
const PAGES_DIR = path.join(process.cwd(), "src", "pages");

// üß© Function: ‡¶∏‡¶¨ page ‡¶•‡ßá‡¶ï‡ßá route ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ
function getRoutesFromPages(dir) {
  if (!fs.existsSync(dir)) {
    console.error(`‚ùå Pages directory not found: ${dir}`);
    return [];
  }

  const files = fs.readdirSync(dir);
  const routes = [];

  files.forEach((file) => {
    const fullPath = path.join(dir, file);
    const stats = fs.statSync(fullPath);

    if (stats.isDirectory()) {
      routes.push(...getRoutesFromPages(fullPath));
    } else if (file.endsWith(".jsx")) {
      let route = "/" + file.replace(".jsx", "").toLowerCase();

      // üè† Home page handle
      if (["home.jsx", "index.jsx"].includes(file.toLowerCase())) route = "";

      routes.push(route);
    }
  });

  return routes;
}

// üìú Generate routes
const routes = getRoutesFromPages(PAGES_DIR);
const today = new Date().toISOString().split("T")[0];

// üßæ Sitemap XML ‡¶§‡ßà‡¶∞‡¶ø
let xml = `<?xml version="1.0" encoding="UTF-8"?>\n`;
xml += `<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n`;

routes.forEach((route) => {
  xml += `  <url>\n`;
  xml += `    <loc>${BASE_URL}${route}</loc>\n`;
  xml += `    <lastmod>${today}</lastmod>\n`;
  xml += `    <changefreq>weekly</changefreq>\n`;
  xml += `    <priority>${route === "" ? "1.0" : "0.8"}</priority>\n`;
  xml += `  </url>\n`;
});

xml += `</urlset>`;

// üìÅ Output Folder (frontend/public)
const OUTPUT_DIR = path.join(process.cwd(), "public");

// ‡¶Ø‡¶¶‡¶ø public folder ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶¨‡ßá
if (!fs.existsSync(OUTPUT_DIR)) {
  fs.mkdirSync(OUTPUT_DIR, { recursive: true });
}

// ‚úçÔ∏è sitemap.xml ‡¶´‡¶æ‡¶á‡¶≤ ‡¶≤‡¶ø‡¶ñ‡¶¨‡ßá
fs.writeFileSync(path.join(OUTPUT_DIR, "sitemap.xml"), xml, "utf8");
console.log(`‚úÖ Sitemap generated successfully with ${routes.length} pages.`);

// ü§ñ robots.txt ‡¶§‡ßà‡¶∞‡¶ø/‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá
const robotsTxt = `User-agent: *
Allow: /

Sitemap: ${BASE_URL}/sitemap.xml
`;

fs.writeFileSync(path.join(OUTPUT_DIR, "robots.txt"), robotsTxt, "utf8");
console.log("‚úÖ robots.txt created/updated successfully.");
